{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import csv\n",
    "import requests\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the institue links, we need those to scrape info about schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "institute_link = []\n",
    "link_ids = {}\n",
    "\n",
    "with open(\"data/infoscuola-database.json\",\"r\") as f:\n",
    "    for school_info in file_data['data']:\n",
    "\n",
    "        institute_name = school_info[0].split('\"')\n",
    "        link_info = institute_name[1].split(\"/\")\n",
    "        id_link = link_info[-1]\n",
    "        \n",
    "        if(id_link not in link_ids):\n",
    "            institute_link.append(institute_name[1])\n",
    "            link_ids[id_link] = True\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting school links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id to look for in the HTML: table-unita-scolastiche\n",
    "schools_link = []\n",
    "\n",
    "for link in institute_link:\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.content,\"html.parser\")\n",
    "    table = soup.find(\"table\",attrs={'id':'table-unita-scolastiche'})\n",
    "    tbody = table.find(\"tbody\")\n",
    "    a_tags = tbody.findAll([\"a\"],href=True)\n",
    "\n",
    "    for a_tag in a_tags:\n",
    "        schools_link.append(\"https://www.vivoscuola.it\"+a_tag['href'])\n",
    "    random.uniform(0.9,1.2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/schoo_links.txt', 'w') as f:\n",
    "    for line in schools_link:\n",
    "        f.write(f\"{line}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now parse school details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_link = []\n",
    "with open(\"data/schoo_links.txt\",\"r\") as f:\n",
    "    schools_link = f.readlines()\n",
    "\n",
    "schools_details = []\n",
    "\n",
    "for link in schools_link:\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.content,\"html.parser\")\n",
    "\n",
    "    entry = [None,None,None,None,None,None,None,None,None,None]\n",
    "    school_info = {\n",
    "        \"Tipo scuola\":[0,None],\n",
    "        \"Indirizzo\":[0,None],\n",
    "        \"Telefono\":[0,None],\n",
    "        \"Fax\":[0,None],\n",
    "        \"Email istituto\":[0,None],\n",
    "        \"Email dirigenza\":[0,None],\n",
    "        \"Email segreteria\":[0,None],\n",
    "        \"Sito web\":[0,None],\n",
    "        \"Codice MIUR\":[0,None],\n",
    "    }\n",
    "    title = soup.find(\"div\",attrs={'class':'u-content-title'})\n",
    "    entry[9] = title.text\n",
    "            \n",
    "    main_div = soup.find(\"div\",attrs={'class':\"Grid Prose u-padding-top-xxl\"})\n",
    "        \n",
    "    info_descriptions = main_div.select(\"div[class*=u-textItalic]\")\n",
    "\n",
    "    for index,info in enumerate(info_descriptions):\n",
    "        school_info[info.text.strip()] = [index,info.text.strip()]\n",
    "    general_infos = main_div.select(\"div[class*=u-size3of4]\")\n",
    "\n",
    "    for index,key in enumerate(school_info):\n",
    "        if(school_info[key][1] != None):\n",
    "            entry[index] = general_infos[school_info[key][0]].text.strip()\n",
    "    \n",
    "    \n",
    "    schools_details.append(entry)\n",
    "    random.uniform(0.9,1.4)\n",
    "    \n",
    "#scripts = soup.find_all(\"script\")\n",
    "#pattern = re.compile('var provincecode (.*?)',re.MULTILINE)\n",
    "#for script in scripts:\n",
    "#    print(script)\n",
    "#    if(pattern.match(str(script.string))):\n",
    "#        data = pattern.match(script.string)\n",
    "#        print(data)\n",
    "#    break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we now clean the scraped data and save it on a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for school in schools_details:\n",
    "    school[9] = ''.join(school[9].splitlines())\n",
    "    school[1] = ''.join(school[1].splitlines())\n",
    "\n",
    "    for item in school:\n",
    "        if(item != None):\n",
    "            item = re.sub(' +', ' ', item)\n",
    "\n",
    "with open(\"data/school_list.csv\",\"w\",newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"school_type\",\"address\",\"phone_number\",\"fax_number\",\"school_email\",\"management_email\",\"office_email\",\"website\",\"miur_code\",\"school_name\"])\n",
    "    writer.writerows(schools_details)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('kge')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10537ea51c3dc610b1a1b8668135cecc6661dce9d1e3cc4968c03d22fc8681e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
