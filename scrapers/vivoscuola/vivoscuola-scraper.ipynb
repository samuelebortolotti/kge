{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import csv\n",
    "import requests\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the institue links, we need those to scrape info about schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "institute_link = []\n",
    "link_ids = {}\n",
    "\n",
    "with open(\"data/infoscuola-database.json\",\"r\") as f:\n",
    "    file_data = json.load(f)\n",
    "    for school_info in file_data['data']:\n",
    "\n",
    "        institute_name = school_info[0].split('\"')\n",
    "        link_info = institute_name[1].split(\"/\")\n",
    "        id_link = link_info[-1]\n",
    "        \n",
    "        if(id_link not in link_ids):\n",
    "            institute_link.append(institute_name[1])\n",
    "            link_ids[id_link] = True\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting school links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id to look for in the HTML: table-unita-scolastiche\n",
    "schools_link = []\n",
    "\n",
    "for link in institute_link:\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.content,\"html.parser\")\n",
    "    table = soup.find(\"table\",attrs={'id':'table-unita-scolastiche'})\n",
    "    tbody = table.find(\"tbody\")\n",
    "    a_tags = tbody.findAll([\"a\"],href=True)\n",
    "\n",
    "    for a_tag in a_tags:\n",
    "        schools_link.append(\"https://www.vivoscuola.it\"+a_tag['href'])\n",
    "    random.uniform(0.9,1.2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/schoo_links.txt', 'w') as f:\n",
    "    for line in schools_link:\n",
    "        f.write(f\"{line}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now parse school details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_link = []\n",
    "with open(\"data/schoo_links.txt\",\"r\") as f:\n",
    "    schools_link = f.readlines()\n",
    "\n",
    "schools_details = []\n",
    "\n",
    "for link in schools_link:\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.content,\"html.parser\")\n",
    "\n",
    "    entry = [None,None,None,None,None,None,None,None,None,None]\n",
    "    school_info = {\n",
    "        \"Tipo scuola\":[0,None],\n",
    "        \"Indirizzo\":[0,None],\n",
    "        \"Telefono\":[0,None],\n",
    "        \"Fax\":[0,None],\n",
    "        \"Email istituto\":[0,None],\n",
    "        \"Email dirigenza\":[0,None],\n",
    "        \"Email segreteria\":[0,None],\n",
    "        \"Sito web\":[0,None],\n",
    "        \"Codice MIUR\":[0,None],\n",
    "    }\n",
    "    title = soup.find(\"div\",attrs={'class':'u-content-title'})\n",
    "    entry[9] = title.text\n",
    "            \n",
    "    main_div = soup.find(\"div\",attrs={'class':\"Grid Prose u-padding-top-xxl\"})\n",
    "        \n",
    "    info_descriptions = main_div.select(\"div[class*=u-textItalic]\")\n",
    "\n",
    "    for index,info in enumerate(info_descriptions):\n",
    "        school_info[info.text.strip()] = [index,info.text.strip()]\n",
    "    general_infos = main_div.select(\"div[class*=u-size3of4]\")\n",
    "\n",
    "    for index,key in enumerate(school_info):\n",
    "        if(school_info[key][1] != None):\n",
    "            entry[index] = general_infos[school_info[key][0]].text.strip()\n",
    "    \n",
    "    \n",
    "    schools_details.append(entry)\n",
    "    random.uniform(0.9,1.4)\n",
    "    \n",
    "#scripts = soup.find_all(\"script\")\n",
    "#pattern = re.compile('var provincecode (.*?)',re.MULTILINE)\n",
    "#for script in scripts:\n",
    "#    print(script)\n",
    "#    if(pattern.match(str(script.string))):\n",
    "#        data = pattern.match(script.string)\n",
    "#        print(data)\n",
    "#    break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/school_list_cleaned.csv\",\"w\",newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"school_type\",\"address\",\"phone_number\",\"fax_number\",\"school_email\",\"management_email\",\"office_email\",\"website\",\"miur_code\",\"school_name\"])\n",
    "    writer.writerows(schools_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fetching institutes info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutes_details = []\n",
    "\n",
    "institutes_dropouts = {}\n",
    "\n",
    "for link in institute_link:\n",
    "\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.content,\"html.parser\")\n",
    "\n",
    "    entry = [None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None]\n",
    "    institute_info = {\n",
    "        \"Coordinatore pedagogico\":[0,None],\n",
    "        \"Presidente Ente Gestore\":[0,None],\n",
    "        \"Sorastant de la scola ladines\":[0,None],\n",
    "        \"Tipo istituto\":[0,None],\n",
    "        \"Dirigente scolastico\":[0,None],\n",
    "        \"Direttore\":[0,None],\n",
    "        \"Indirizzo\":[0,None],\n",
    "        \"Telefono\":[0,None],\n",
    "        \"Fax\":[0,None],\n",
    "        \"Email istituto\":[0,None],\n",
    "        \"Email dirigenza\":[0,None],\n",
    "        \"Email segreteria\":[0,None],\n",
    "        \"Sito web\":[0,None],\n",
    "        \"Codice MIUR\":[0,None],\n",
    "        \"Numero plessi/scuole\":[0,None]\n",
    "    }    \n",
    "    title = soup.find(\"div\",attrs={'class':'u-content-title'})\n",
    "    entry[15] = title.text\n",
    "            \n",
    "    main_div = soup.find(\"div\",attrs={'class':\"Grid Prose u-padding-top-xxl\"})\n",
    "        \n",
    "    info_descriptions = main_div.select(\"div[class*=u-textItalic]\")\n",
    "\n",
    "    for index,info in enumerate(info_descriptions):\n",
    "        institute_info[info.text.strip()] = [index,info.text.strip()]\n",
    "\n",
    "    general_infos = main_div.select(\"div[class*=u-size3of4]\")\n",
    "\n",
    "    for index,key in enumerate(institute_info):\n",
    "        if(institute_info[key][1] != None):\n",
    "            try:\n",
    "                entry[index] = general_infos[institute_info[key][0]].text.strip()\n",
    "            except IndexError:\n",
    "                print(f\"ERRORE: {link}\")\n",
    "        #aprilascuol\n",
    "    #institutes_dropouts[institute_info[\"Codice MIUR\"]] = [] #nome, [ordine,tipo,abbandoni,iscritti]\n",
    "\n",
    "    aprilascuola = soup.find(\"div\",attrs={'class':'aprilascuolaaffix'})\n",
    "    dropdown = aprilascuola.find(\"div\", attrs={'class':'dropdown'})\n",
    "    menu = dropdown.find(\"div\",attrs={'class':\"dropdown-menu\"})\n",
    "    list_items = menu.find_all(\"li\")\n",
    "    for item in list_items:\n",
    "        span = item.find(\"span\")\n",
    "        if(\"Abbandono\" in span.text):\n",
    "            a_tag = item.find(\"a\")\n",
    "            institutes_dropouts[entry[13]] = []\n",
    "            institutes_dropouts[entry[13]].append(\"https://www.vivoscuola.it\"+a_tag['href'])\n",
    "    \n",
    "    \n",
    "    institutes_details.append(entry)\n",
    "    random.uniform(0.9,1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"data/institutes_list.csv\",\"w\",newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"coordinatore_pedagogico\",\n",
    "    \"presidente_ente_gestore\",\n",
    "    \"sorastant\",\n",
    "    \"tipo_instituto\",\n",
    "    \"dirigente_scolastico\",\n",
    "    \"direttore\",\n",
    "    \"indirizzo\",\n",
    "    \"telefono\",\n",
    "    \"fax\",\n",
    "    \"email_istituto\",\n",
    "    \"email_dirigenza\",\n",
    "    \"email_segreteria\",\n",
    "    \"sito_web\",\n",
    "    \"miur_code\",\n",
    "    \"numero_plessi_scuole\",\n",
    "    \"nome_istituto\"])\n",
    "    writer.writerows(institutes_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we now parse dropouts rate using information gained in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutes_dropouts_data = []\n",
    "\n",
    "api_code_per_link = []\n",
    "for item in institutes_dropouts:\n",
    "    link = institutes_dropouts[item][0]\n",
    "    print(link)\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.content,\"html.parser\")\n",
    "\n",
    "    scripts  = soup.find_all(\"script\",{\"scr\":False})\n",
    "\n",
    "    p = re.compile('var provincecode = (.*);')        \n",
    "    for script in scripts:\n",
    "        if(\"provincecode\" in script.text):\n",
    "            match = p.search(script.string)\n",
    "            api_code = match.group(1)\n",
    "            if(api_code[0] == '\"'):\n",
    "                api_code = api_code[1:-1]\n",
    "            api_code_per_link.append((item,link,api_code))\n",
    "    random.uniform(0.9,1.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"https://www.istruzione.provincia.tn.it/services/sei/api/v1/institutes/schoolDropout/\"\n",
    "\n",
    "def check_for_key_error(dictionary,key):\n",
    "    if(key not in dictionary):\n",
    "        return None\n",
    "    else:\n",
    "        return dictionary[key]\n",
    "\n",
    "for institute_api_infos in api_code_per_link:\n",
    "    miur_code,link,api_code = institute_api_infos\n",
    "    response = requests.get(url=endpoint+api_code)\n",
    "    data = response.json()\n",
    "\n",
    "    for entry in data['listaDati']:\n",
    "        #dataInserimento\n",
    "        #ordScolCap -> tipo scuola\n",
    "        #ordScolOrd\n",
    "        #struttLiv1Cap\n",
    "        #struttLiv1Miur\n",
    "        #struttLiv1CodPat\n",
    "        #tipoOraId\n",
    "        #valore -> abbandoni\n",
    "        #valoreD -> iscritti\n",
    "        #valoreN -> boh\n",
    "        #miurocode del ciclo (per vedere se combaciano),\n",
    "        \n",
    "        institutes_dropouts_data.append([\n",
    "            check_for_key_error(entry,'dataInserimento'),\n",
    "            check_for_key_error(entry,'ordScolCap'),\n",
    "            check_for_key_error(entry,'ordScolOrd'),\n",
    "            check_for_key_error(entry,'struttLiv1Cap'),\n",
    "            check_for_key_error(entry,'struttLiv1CodMiur'),\n",
    "            check_for_key_error(entry,'struttLiv1CodPat'),\n",
    "            check_for_key_error(entry,'tipoOraId'),\n",
    "            check_for_key_error(entry,'valore'),\n",
    "            check_for_key_error(entry,'valoreD'),\n",
    "            check_for_key_error(entry,'valoreN'),\n",
    "            miur_code\n",
    "        ])\n",
    "\n",
    "    random.uniform(.9,1.2)\n",
    "\n",
    "with open(\"data/institute_droputs.csv\",\"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"data_inserimento\",\"ord_scol_cap\",\"ord_scol_ord\",\"strutt_liv_1_cap\",\"strutt_liv_1_cod_miur\",\"strutt_liv_1_cod_pat\",\"tipo_ora_id\",\"valore\",\"valore_d\",\"valore_n\",\"miur_code\"])\n",
    "    writer.writerows(institutes_dropouts_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('kge')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10537ea51c3dc610b1a1b8668135cecc6661dce9d1e3cc4968c03d22fc8681e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
